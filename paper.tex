\documentclass{llncs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{tikz}
\usetikzlibrary{trees}

\algnewcommand{\IIf}[1]{\State\algorithmicif\ #1\ \algorithmicthen}
\algnewcommand{\EndIIf}{}

\pagestyle{headings}

\begin{document}

\title{Untitled CAV Paper}

\author{Alexander Legg\inst{1} 
    \and Leonid Ryzhyk\inst{2}
    \and Nina Narodytska\inst{2}}

\institute{NICTA\thanks{NICTA is funded by the Australian Government as represented by the Department of Broadband,
    Communications and the Digital Economy and the Australian Research Council through the ICT
    Centre of Excellence program.} and UNSW \\
    \email{alexander.legg@nicta.com.au}
    \and Samsung Research}

\maketitle

\begin{abstract}

    Reactive synthesis techniques based on image computations have been shown
    to work well in many cases but suffer from state explosion in others.
    A different approach applies SAT solvers in a counterexample guided framework but
    is limited to bounded synthesis.  We present an extension of this technique
    to unbounded synthesis by employing interpolation.  Experimental results
    show this to be a promising alternative that solves some previously
    intractable instances.

\end{abstract}

\section{Introduction}

Reactive systems are ubiquitous in real-world problems such as circuit design,
industrial automation, or device drivers. Automatic synthesis can provide a
\emph{correct by construction} controller for a reactive system from a
specification.  However, the reactive synthesis problem is 2EXPTIME-complete so
naive algorithms are infeasible on even simple systems.

Reactive synthesis is formalised as a game between the \emph{controller} and
its \emph{environment}. In this work we focus on safety games, in which the
controller must prevent the environment from forcing the game into an error
state.  Much of the complexity of reactive synthesis stems from tracking the
set of states in which a player is winning.

There are several techniques that aim to mitigate this complexity by
representing states symbolically.  Historically the most successful technique
has been to use \emph{Binary Decision Diagrams} (BDDs).  BDDs efficiently
represent a relation on a set of game variables but in the worst case the
representation may be exponential. This means that BDDs are not a
one-size-fits-all solution for all reactive synthesis specifications.

Advances in SAT solving technology has prompted research into its applicability
to synthesis as an alternative to BDDs. One approach is to find sets of states
in CNF \cite{demiurge}. Another approach is to eschew states and focus on
\emph{runs} of the game. Previous work has applied this idea to realizability
of bounded games \cite{narodytska2014} by forming abstract representations of
the game.  In this paper, we extend this idea to unbounded games by
constructing approximate sets of winning states from abstract trees.

\section{Reactive Synthesis}

A \emph{safety game}, $G = \langle X, L_u, L_c, \delta, I, E, \rangle$,
consists of a set of boolean state variables, sets of uncontrollable and
controllable label variables, a transition relationship $\delta : (X, L_u, L_c)
\to X$, an initial state, and an error state. The \emph{controller} and
\emph{environment} players choose controllable and uncontrollable labels
respectively and the game proceeds according to $\delta$. 

An \emph{run} of a game $(x_0, u_0, c_0), (x_1, u_1, c_1) \dots (x_n, u_n,
c_n)$ is a chain of state and label pairs of length $n$ s.t.  $x_{k+1}
\leftarrow \delta(x_k, u_k, c_k)$. A run is winning for the controller if $x_0
= I \land \forall i \in \{1..n\} (x_i \neq E)$. In a bounded game of rank $n$
all runs are restricted to length $n$, whereas unbounded games consider runs of
infinite length. Since we consider only deterministic games a run is equivalent
to a list of assignments to $L_c$ and $L_u$.

A \emph{controller strategy} $\pi^c : (X, L_u) \to L_c$ is a mapping of states
and uncontrollable inputs to controllable labels. A controller strategy is
winning in a bounded game of rank $n$ if all runs $(x_0, u_0, \pi^c(x_0, u_0)),
(x_1, u_1, \pi^c(x_1, u_1)) \dots (x_n, u_n, \pi^c(x_n, u_n))$ are winning.
Bounded \emph{realizability} is the problem of determining the existence of
such a strategy for a bounded game.

An \emph{environment strategy} $\pi^e : X \to L_u$ is a mapping of states to
uncontrollable labels. A bounded run is winning for the environment if $x_0
= I \land \exists i \in \{1..n\} (x_i = E)$ and an environment strategy is
winning for a bounded game if there exists a run $(x_0, \pi^e(x_1), c_1), (x_1,
\pi^e(x_1), c_1) \dots (x_n, \pi^e(x_n), c_n)$ that wins for the environment.
Safety games are zero sum, therefore the existence of a controller strategy
implies the nonexistence of an environment strategy and vice versa.

\subsection{Abstract Game Trees}

A set of runs can be represented symbolically by a tree of valuations to
controllable and uncontrollable label variables where valuations are allowed to
be \emph{unfixed}. An unfixed value symbolically represents all possible
valuations. Formally, we define the tree as a set of lists of label valuations
and a node in the tree may be identified by the list made by following the path
from the root.

The entire set of runs of a bounded game of rank $n$ is
symbolically represented by a tree of depth $2n$ and width 1 populated by
unfixed edges.  Reducing the set of runs in a game forms an abstract game,
which can be represented symbolically by an \emph{abstract game tree}.

A strategy is equivalent to the set of all runs with the player's labels
obeying the strategy mapping $\pi$. Therefore, a strategy can also be
represented by a tree. Relaxing the restriction of the strategy mapping allows
for a \emph{partial strategy} in which multiple labels are now possible for a
single state.

A strategy or partial strategy can also be thought of as an abstract game. A
partial strategy for the controller is a restriction only on the controllable
labels in the game. So if the environment can not win in the abstract game
equivalent to the controller's partial strategy, then all strategies allowable
by that partial strategy must be winning.

An abstract game tree can be checked for the existence of a winning run by a
SAT solver\cite{narodytska2014}.  The tree must be encoded into CNF by making
copies of the transition relation for each game step in tree. The formula must
also check whether the error state has been reached in no branch/in all
branches for the controller and environment respectively. The functions that
produce these formulas are shown in Algorithm \ref{alg:treeFormula}.

\begin{algorithm}
    \caption{Tree formulas for Controller and Environment respectively}
    \label{alg:treeFormula}
    \begin{algorithmic}
        \Function{treeFormula}{gt}
        \If{$\Call{rank}{gt} == 0$}
        \State \Return{ $\lnot \Call{E}{x^{gt}}$ }
        \Else
        \State \Return{ $\lnot \Call{E}{x^{gt}} \land \bigwedge_{n \in \Call{succ}{gt}}(\Call{$\delta$}{n} \land \Call{label}{n} \land \Call{treeFormula}{n})$ }
        \EndIf
        \EndFunction
    \end{algorithmic}

    \begin{algorithmic}
        \Function{$\overline{treeFormula}$}{gt}
        \If{$\Call{rank}{gt} == 0$}
        \State \Return{\Call{E}{$x^{gt}$}}
        \Else
        \State \Return{ $\Call{E}{x^{gt}} \lor \bigvee_{n \in \Call{succ}{gt}}(\Call{$\delta$}{n} \land \Call{label}{n} \land \Call{$\overline{treeFormula}$}{n})$ }
        \EndIf
        \EndFunction
    \end{algorithmic}
\end{algorithm}

When we produce a formula using $\textsc{treeFormula}$ the SAT solver is
playing on behalf on the controller. Any unfixed labels in the tree,
controllable or uncontrollable, will be existentially quantified.  This means
that if there exists a way for the game to be solved when both players
cooperate the SAT solver will find it. If no winning run exists in an abstract
game even when the players are cooperating then there is definitely no winning
run when the opponent is playing adversarily.

\subsection{Counterexample Guided Bounded Synthesis}

By checking for the existence of a winning run for the environment in an
abstract game tree constructed from a partial controller strategy we are
checking if the partial strategy is winning. If no spoiling run can be found
then the partial strategy must always win. If a spoiling run is found then we
then we have a counterexample that proves that the controller strategy is not
winning. This forms the basis of a counterexample guided abstraction refinement
framework that operates on candidate strategies.

The bounded synthesis algorithm described in \cite{narodytska2014} begins with
an empty game as seen in Figure \ref{fig:emptytree}.  Initially we are playing
on behalf of the environment because it chooses the first move in each step.
The empty game is passed to the SAT solver, which searches for a candidate
environment strategy.  If a candidate is found (Figure \ref{fig:candidate})
then it is checked for a spoiling strategy by solving for the controller.  If
no spoiling strategy exists, that means our candidate is a winning strategy and
the algorithm terminates.  Otherwise we find a counterexample (Figure
\ref{fig:cex}), which is used to refine the empty game tree to include the
first move from the controller's spoiling strategy (Figure \ref{fig:refined}.
The algorithm continues by finding a new candidate for the environment (Figure
\ref{fig:candidate2}), and a new counterexample to refine the game abstraction
once again (Figure \ref{fig:refined2}).


\tikzset{every node/.style={solid}}
\tikzstyle{fixed}=[solid]
\tikzstyle{unfixed}=[dash pattern = on 2pt off 2pt]
\begin{figure}
    \centering
    \begin{subfigure}{.3\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root){}
                child {node [circle,draw] {} edge from parent[unfixed]
                    child {node [circle,draw] {} edge from parent[unfixed]}
                };
        \end{tikzpicture}
        \caption{An empty AGT}
        \label{fig:emptytree}
    \end{subfigure}%
    \begin{subfigure}{.35\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root) {}
                child {node [circle,draw] {}
                    child {node [circle,draw] {} edge from parent[unfixed]}
                    edge from parent [fixed] node [left] {$u_1$}
                };
        \end{tikzpicture}
        \caption{Environment candidate}
        \label{fig:candidate}
    \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root){}
                child {node [circle,draw] {} edge from parent[unfixed]
                    child {node [circle,draw] {} edge from parent[fixed] node [left] {$c_1$}}
                    edge from parent [fixed] node [left] {$u_1$}
                };
        \end{tikzpicture}
        \caption{Counterexample}
        \label{fig:cex}
    \end{subfigure}


    \begin{subfigure}{.3\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root){}
                child {node [circle,draw] {} edge from parent[unfixed]
                    child {node [circle,draw] {} edge from parent[fixed] node [left] {$c_1$}}
                };
        \end{tikzpicture}
        \caption{Refined AGT}
        \label{fig:refined}
    \end{subfigure}%
    \begin{subfigure}{.35\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root) {}
                child {node [circle,draw] {}
                    child {node [circle,draw] {} edge from parent[unfixed]}
                    edge from parent [fixed] node [left] {$u_2$}
                };
        \end{tikzpicture}
        \caption{New candidate}
        \label{fig:candidate2}
    \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
        \centering
        \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
            \node [circle,draw] (root){}
                child {node [circle,draw] {} edge from parent[unfixed]
                    child {node [circle,draw] {} edge from parent[fixed] node [left] {$c_1$}}
                    child {node [circle,draw] {} edge from parent[fixed] node [right] {$c_2$}}
                };
        \end{tikzpicture}
        \caption{Refined AGT}
        \label{fig:refined2}
    \end{subfigure}
    \caption{Abstract game trees}
\end{figure}

\begin{algorithm}
    \begin{algorithmic}
        \Function{solveAbstract}{$\langle s, r \rangle , gt$}
        \State $cand \gets $ \Call{findCandidate}{$\langle s, r \rangle, gt$}
        \IIf{$r = n - 1$} \Return $cand$ \EndIIf 
        \State $gt' \gets gt$
        \Loop
            \IIf{$cand = \emptyset $} \Return $\emptyset $ \EndIIf
            \State $cex \gets $ \Call{verify}{$\langle s, r \rangle, gt, cand$}
            \IIf{$cex = NULL$} \Return $cand$ \EndIIf
            \State $gt' \gets gt' \cup cex$
%%%            \State $gt' \gets \Call{refine}{gt', cex}$
            \State $cand \gets $ \Call{solveAbstract}{$\langle s, r \rangle, gt'$}
        \EndLoop
        \EndFunction
    \end{algorithmic}

%%%    \begin{algorithmic}
%%%        \Function{refine}{$gt, \langle leaf, spoiling \rangle$}
%%%            \State \Return $gt \cup \{leaf, spoiling\}$
%%%        \EndFunction
%%%    \end{algorithmic}

    \begin{algorithmic}
        \Function{findCandidate}{$\langle s, r \rangle, T$}
            \State $\hat{T} \gets \Call{gtExtend}{T}$
            \State $fml \gets $ \Call{treeFormula}{$\hat{T}$}
            \State $sol \gets $ \Call{SAT}{$s(X_T) \land fml$}
        \EndFunction
    \end{algorithmic}

    \begin{algorithmic}
        \Function{verify}{$\langle r, s\rangle, gt, cand$}
            \For{$l \in leaves(gt)$}
                \State $\langle r', s'\rangle \gets $ \Call{outcome}{$\langle r, s\rangle, gt, l$}
                \State $spoiling \gets $ \Call{solveAbstract}{$\langle r', s' \rangle, \emptyset$}
            \EndFor
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\section{Unbounded Synthesis}

Bounded synthesis can be used to prove the existence of a winning strategy for
the environment by providing a witness. For the controller, the strongest claim
that can be made is that the strategy is winning as long as the game does not
extend longer than the bound.

In model checking the maximum bound is decided based on the states of the game
\cite{biere1999}. The na\"ive approach is to use size of the state space as the
bound ($2^{|X|}$). With a bound of this size all states may be explored. One
optimisation is to use the diameter of the game, which is the smallest number
$d$ such that for any state $x$ there is a path of length $\leq d$ to all other
reachable states. However, for large games these bounds are intractable.

When performing model checking or synthesis with BDDs \cite{burch1990} the set
of states that are winning for the environment is iteratively constructed by
computing the states from which the environment can force the game into the
previous winning set. Eventually this process reaches a fixed point and the
total set of environment winning states is known.

A similar concept can be applied to the bounded synthesis algorithm to
iteratively increase the bound of the game and terminate when a fixed point is
reached. When a strategy is found to be winning on an abstract game tree, we
record as winning the states from which the opponent could find no
counterexample. To find these states we use interpolation of subformulas of the
game tree.

\subsection{Learning States with Interpolants}

Given two formulas $A$ and $B$ such that $A \land B$ is unsatisfiable, it is
possible to construct and interpolant $\mathcal{I}$ such that $A \to
\mathcal{I}$, $B \land \mathcal{I}$ is unsatisfiable, and $\mathcal{I}$ refers
only to the intersection of variables in $A$ and $B$. An interpolant can be
constructed efficiently from a resolution proof of the unsatisfiability of $A
\land B$ \cite{pudlak1997}.

\begin{figure}
    \centering
    \begin{tikzpicture}[dash pattern = on 2pt off 2pt, level distance = 10mm]
        \node [] (root){}
            child {node [circle,draw,label=left:$x_1$] {}
                child {node [circle,draw] {}
                    child {node [circle,draw,label=left:$x_0^0$] {} edge from parent[unfixed]}
                    edge from parent [fixed] node [left] {$u_1$}
                }
                child {node [circle,draw] {} edge from parent[unfixed]
                    child {node [circle,draw,label=right:$x_0^1$] {} edge from parent[unfixed]}
                    edge from parent [fixed] node [right] {$u_2$}
                }
                edge from parent [unfixed]
            };
    \end{tikzpicture}
%%%    \begin{tikzpicture}[overlay]
%%%        \draw [rotate = -20] (-1.9,0.35) ellipse (0.7 and 1.3);
%%%    \end{tikzpicture}
    \caption{A controller-losing game tree}
    \label{fig:interpolatetree}
\end{figure}

Consider the snippet of a game tree in Figure \ref{fig:interpolatetree}. The
tree is losing for the controller, the node labelled $x_1$ is at rank 1, and
$x_0^0$ and $x_0^1$ are at rank 0. Since the tree is controller-losing we know
that at least one run represented by the tree contains the error state.  As
a result, $\textsc{treeFormula}(gt)$ is unsatisfiable. If we take the step
$x_1$ to $x_0^0$ and cut it from the rest of the tree then
$\textsc{treeFormula}(step) \land \textsc{treeFormula}(parent)$ must still be
unsatisfiable.

We can construct an interpolant with $A = \textsc{treeFormula}(parent)$ and $B
= \textsc{treeFormula}(step)$. The only variables shared between $A$ and $B$
are the state variables at $x_1$. We know that $B \land \mathcal{I}$ is
unsatisfiable, therefore all states in $\mathcal{I}$ must lose to the
uncontrollable label $u_1$. We also know that $A \to \mathcal{I}$, thus
$\mathcal{I}$ contains all states reachable by the parent tree (on runs that
avoid the error state.)

\begin{algorithm}
    \caption{Amended tree formulas for Controller and Environment respectively}
    \label{alg:treeFormula}
    \begin{algorithmic}
        \Function{treeFormula}{gt}
        \If{$\Call{rank}{gt} == 0$}
        \State \Return{ $\lnot \Call{$L^c$}{x^{gt}}$ }
        \Else
        \State \Return{ $\lnot \Call{$L^c$}{x^{gt}} \land \bigwedge_{n \in \Call{succ}{gt}}(\Call{$\delta$}{n} \land \Call{label}{n} \land \Call{treeFormula}{n})$ }
        \EndIf
        \EndFunction
    \end{algorithmic}

    \begin{algorithmic}
        \Function{$\overline{treeFormula}$}{gt}
        \If{$\Call{rank}{gt} == 0$}
        \State \Return{\Call{E}{$x^{gt}$}}
        \Else
        \State \Return{ $\Call{$L^e[rank(gt)]$}{x^{gt}} \land$ \\
            $(\Call{E}{x^{gt}} \lor \bigvee_{n \in \Call{succ}{gt}}(\Call{$\delta$}{n} \land \Call{label}{n} \land \Call{$\overline{treeFormula}$}{n}))$ }
        \EndIf
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Now we can consider the step $x_1$ to $x_0^1$, and the parent - now without
either $x_1 \to x_0^0$ or $x_1 \to x_0^1$. The formula
$(\textsc{treeFormula}(parent) \land \mathcal{I}) \land
\textsc{treeFormula}(step)$ must be unsatisfiable. $\mathcal{I}$ contains all
states that lose to $u_1$ so any other state reachable at $x_1$ must lose to
$u_2$. Therefore we can compute another interpolant that contains states that
lose to $u_2$.

This is the foundation for a recursive algorithm that consumes an entire tree
by removing a single step on each iteration. All learned states from which the
controller must lose are recorded in a set $L^c$.  This algorithm can also be
performed on environment-losing trees with the caveat that any state learnt at
a node of rank $n$ is only known to lose at ranks less than or equal to $n$. 

\subsection{Proof of Termination}

\subsection{Algorithm}

\section{Evaluation}

\section{Related Work}

\section{Conclusion}


\bibliographystyle{splncs03}
\bibliography{paper}

\end{document}
